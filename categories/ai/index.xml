<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on Bits&amp;Brains</title><link>https://sarckk.github.io/categories/ai/</link><description>Recent content in AI on Bits&amp;Brains</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 10 Apr 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://sarckk.github.io/categories/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>Grokking Transformers (WIP)</title><link>https://sarckk.github.io/post/2023/04/10/grokking-transformers-wip/</link><pubDate>Mon, 10 Apr 2023 00:00:00 +0000</pubDate><guid>https://sarckk.github.io/post/2023/04/10/grokking-transformers-wip/</guid><description>Today&amp;rsquo;s Large Language Models (LLM) are based on Transformers, a deep learning model architecture for sequence-to-sequence transformations based on the attention mechanism. While it was originally proposed and used in Natural Language Processing (NLP) tasks like language translation, it turns out that a lot of things that we care about can be modelled in terms of sequences, making transformers a useful model in a wide variety of applications beyond NLP, such as image processing and reinforcement learning .</description></item><item><title>Programming with Bing Chat</title><link>https://sarckk.github.io/post/2023/04/07/programming-with-bing-chat/</link><pubDate>Fri, 07 Apr 2023 00:00:00 +0000</pubDate><guid>https://sarckk.github.io/post/2023/04/07/programming-with-bing-chat/</guid><description>It&amp;rsquo;s been roughly 3 weeks since the release of GPT-4. In the world of AI that means I&amp;rsquo;m already late to the party, but with extra time this week I thought I&amp;rsquo;d finally start playing around with it to see what it can do. People have already started leveraging the power of GPT-4 to create impressive projects, like @ammaar who used GPT-4 and other AI tools like MidJourney to create a 3D game in Javascript from scratch and @mortenjust who made and published an iOS app by prompting GPT-4.</description></item><item><title>Convolutional Neural Networks from Scratch</title><link>https://sarckk.github.io/post/2022/03/20/convolutional-neural-networks-from-scratch/</link><pubDate>Sun, 20 Mar 2022 00:00:00 +0000</pubDate><guid>https://sarckk.github.io/post/2022/03/20/convolutional-neural-networks-from-scratch/</guid><description>In this blog post we are going to take a look at how to implement a simple CNN model from scratch in Python, using mostly just numpy.
In practice, we can use high-level libraries such as Keras or PyTorch to abstract away the underlying details of CNN when writing code. However, we find that the exercise of writing one from scratch is very helpful in gaining a deeper understanding of CNNs and how these frameworks work under the hood.</description></item></channel></rss>